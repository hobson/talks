<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title>TFNW BYOB</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link rel="stylesheet" href="css/reveal.css"/>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="css/theme/moon.css" id="theme">
  <!-- If the query includes 'print-pdf', include the PDF print sheet -->
  <script>
    if( window.location.search.match( /print-pdf/gi ) ) {
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = 'css/print/pdf.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
  </script>
  <!--[if lt IE 9]>
  <script src="lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">TFNW BYOB</h1>
    <h3 class="date"></h3>
</section>

<section id="tfnw-byob" class="slide level1">
<h1>TFNW <a href="http://totalgood.github.io/talks/2015-08-22-TFNW-BYO-Brain-Workshop.html">BYOB</a></h1>
<h2 id="brains-not-beer"><strong>B</strong>rains not <strong>B</strong>eer</h2>
<ul>
<li>iPython: bit.ly/<a href="https://github.com/totalgood/talks/tree/master/notebooks">TFNWbyob</a></li>
<li>Slides: bit.ly/<a href="http://bit.ly/TFNWbyob">TFNWBYOB</a></li>
</ul>
</section>
<section id="introduction" class="slide level1">
<h1>Introduction</h1>
<h2 id="contributors">Contributors</h2>
<ul>
<li><script type="text/javascript">
<!--
h='&#116;&#x6f;&#116;&#x61;&#108;&#x67;&#x6f;&#x6f;&#100;&#46;&#x63;&#x6f;&#x6d;&#x3f;&#x53;&#x75;&#98;&#106;&#x65;&#x63;&#116;&#x3d;&#66;&#x59;&#x4f;&#x25;&#50;&#48;&#66;&#114;&#x61;&#x69;&#110;&#x25;&#50;&#48;&#x57;&#x6f;&#114;&#x6b;&#x73;&#104;&#x6f;&#112;';a='&#64;';n='&#104;&#x6f;&#98;&#x73;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'">'+'Hobson'+'<\/'+'a'+'>');
// -->
</script><noscript>&#72;&#x6f;&#98;&#x73;&#x6f;&#110;&#32;&#40;&#104;&#x6f;&#98;&#x73;&#32;&#x61;&#116;&#32;&#116;&#x6f;&#116;&#x61;&#108;&#x67;&#x6f;&#x6f;&#100;&#32;&#100;&#x6f;&#116;&#32;&#x63;&#x6f;&#x6d;&#x3f;&#x53;&#x75;&#98;&#106;&#x65;&#x63;&#116;&#x3d;&#66;&#x59;&#x4f;&#x25;&#50;&#48;&#66;&#114;&#x61;&#x69;&#110;&#x25;&#50;&#48;&#x57;&#x6f;&#114;&#x6b;&#x73;&#104;&#x6f;&#112;&#x29;</noscript></li>
<li><script type="text/javascript">
<!--
h='&#116;&#104;&#x65;&#x77;&#x65;&#108;&#108;&#x73;&#46;&#x6f;&#114;&#x67;&#x3f;&#x53;&#x75;&#98;&#106;&#x65;&#x63;&#116;&#x3d;&#66;&#x59;&#x4f;&#x25;&#50;&#48;&#66;&#114;&#x61;&#x69;&#110;&#x25;&#50;&#48;&#x53;&#108;&#x69;&#100;&#x65;&#x73;';a='&#64;';n='&#x63;&#104;&#x69;&#x63;&#x6b;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'">'+'Chick'+'<\/'+'a'+'>');
// -->
</script><noscript>&#x43;&#104;&#x69;&#x63;&#x6b;&#32;&#40;&#x63;&#104;&#x69;&#x63;&#x6b;&#32;&#x61;&#116;&#32;&#116;&#104;&#x65;&#x77;&#x65;&#108;&#108;&#x73;&#32;&#100;&#x6f;&#116;&#32;&#x6f;&#114;&#x67;&#x3f;&#x53;&#x75;&#98;&#106;&#x65;&#x63;&#116;&#x3d;&#66;&#x59;&#x4f;&#x25;&#50;&#48;&#66;&#114;&#x61;&#x69;&#110;&#x25;&#50;&#48;&#x53;&#108;&#x69;&#100;&#x65;&#x73;&#x29;</noscript></li>
<li><script type="text/javascript">
<!--
h='&#x67;&#x6d;&#x61;&#x69;&#108;&#46;&#x63;&#x6f;&#x6d;&#x3f;&#x53;&#x75;&#98;&#106;&#x65;&#x63;&#116;&#x3d;&#66;&#x59;&#x4f;&#x25;&#50;&#48;&#66;&#114;&#x61;&#x69;&#110;&#x25;&#50;&#48;&#72;&#x79;&#112;&#x65;&#114;&#x6f;&#112;&#116;&#x25;&#50;&#48;&#84;&#x61;&#108;&#x6b;';a='&#64;';n='&#x6d;&#x65;&#108;&#x61;&#110;&#x67;&#x65;&#46;&#x61;&#x75;&#46;&#98;&#108;&#x65;&#x75;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'">'+'Thunder'+'<\/'+'a'+'>');
// -->
</script><noscript>&#84;&#104;&#x75;&#110;&#100;&#x65;&#114;&#32;&#40;&#x6d;&#x65;&#108;&#x61;&#110;&#x67;&#x65;&#46;&#x61;&#x75;&#46;&#98;&#108;&#x65;&#x75;&#32;&#x61;&#116;&#32;&#x67;&#x6d;&#x61;&#x69;&#108;&#32;&#100;&#x6f;&#116;&#32;&#x63;&#x6f;&#x6d;&#x3f;&#x53;&#x75;&#98;&#106;&#x65;&#x63;&#116;&#x3d;&#66;&#x59;&#x4f;&#x25;&#50;&#48;&#66;&#114;&#x61;&#x69;&#110;&#x25;&#50;&#48;&#72;&#x79;&#112;&#x65;&#114;&#x6f;&#112;&#116;&#x25;&#50;&#48;&#84;&#x61;&#108;&#x6b;&#x29;</noscript></li>
<li><script type="text/javascript">
<!--
h='&#122;&#x65;&#54;&#x6b;&#x65;&#46;&#x63;&#x6f;&#x6d;&#x3f;&#x53;&#x75;&#98;&#106;&#x65;&#x63;&#116;&#x3d;&#66;&#x59;&#x4f;&#x25;&#50;&#48;&#66;&#114;&#x61;&#x69;&#110;&#x25;&#50;&#48;&#x57;&#x6f;&#114;&#x6b;&#x73;&#104;&#x6f;&#112;';a='&#64;';n='&#x6d;&#x65;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'">'+'Zeke'+'<\/'+'a'+'>');
// -->
</script><noscript>&#90;&#x65;&#x6b;&#x65;&#32;&#40;&#x6d;&#x65;&#32;&#x61;&#116;&#32;&#122;&#x65;&#54;&#x6b;&#x65;&#32;&#100;&#x6f;&#116;&#32;&#x63;&#x6f;&#x6d;&#x3f;&#x53;&#x75;&#98;&#106;&#x65;&#x63;&#116;&#x3d;&#66;&#x59;&#x4f;&#x25;&#50;&#48;&#66;&#114;&#x61;&#x69;&#110;&#x25;&#50;&#48;&#x57;&#x6f;&#114;&#x6b;&#x73;&#104;&#x6f;&#112;&#x29;</noscript></li>
<li><a href="//totalgood.com">Total Good</a></li>
</ul>
</section>
<section class="slide level1">

<h2 id="topics">Topics</h2>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>BC</strong>: Before PC</th>
<th style="text-align: left;"> </th>
<th style="text-align: left;"><strong>AD</strong>: After Digital</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Turing</td>
<td style="text-align: left;"> </td>
<td style="text-align: left;">Layers</td>
</tr>
<tr class="even">
<td style="text-align: left;">Logic Gate</td>
<td style="text-align: left;"> </td>
<td style="text-align: left;">Biology</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Neuron</td>
<td style="text-align: left;"> </td>
<td style="text-align: left;">Images</td>
</tr>
<tr class="even">
<td style="text-align: left;">Learning</td>
<td style="text-align: left;"> </td>
<td style="text-align: left;">Time Series</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Automata</td>
<td style="text-align: left;"> </td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">XOR Fail</td>
<td style="text-align: left;"> </td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<div>
<aside class="notes">
    <p>
AI: &quot;Artificial&quot; intelligence -&gt; &quot;machine&quot; intelligence
</p>
    <p>
Think of &quot;artificial&quot; as &quot;pretend&quot;.
</p>
    <p>
or model.
</p>
    <p>
Like the model you have for how society works.
</p>
    <p>
If you are nice people will be nice to you.
</p>
    <p>
If you work hard, you'll get paid by your boss.
</p>
  </aside>
</div>
</section>
<section class="slide level1">

<h2 id="advanced-topics">Advanced Topics</h2>
<ul>
<li>Feedback/Recursion</li>
<li>Optimization</li>
<li>Reinforcement</li>
<li>Dropout</li>
</ul>
</section>
<section class="slide level1">

<h2 id="bonus">Bonus</h2>
<ul>
<li>NN Applications (by Zeke)</li>
<li>NN Tuning (by Thunder)</li>
</ul>
</section>
<section id="history" class="slide level1">
<h1>History</h1>
<ul>
<li class="fragment">1943 MCP neuron (binary logic)</li>
<li class="fragment">1948 Hebbian Learning</li>
<li class="fragment">1958 Rasenblatt Perceptron</li>
<li class="fragment">1964 Kernel Perceptron</li>
<li class="fragment">1969 XOR fail</li>
<li class="fragment">1972 ELIZA vs. Parry</li>
</ul>
<blockquote>
<h2>AI Dies</h2>
</blockquote>
<div>
<aside class="notes">
  <p>
We'll start with a single neuron cell, like biology.
</p>
  <p>
Artificial neurons (perceptrons) need a way to learn.
</p>
  <p>
Two neurons are better than one (required for XOR)
</p>
  <p>
Then I'll show you how to leverage others' code to build a real brain
</p>
  </aside>
</div>
</section>
<section class="slide level1">

<h2 id="its-alive">It's Alive!</h2>
<ul>
<li class="fragment">1970 <a href="http://pmav.eu/stuff/javascript-game-of-life-v3.1.1/">Conway: Game of Life</a></li>
<li class="fragment">1972 [ELIZA]https://en.wikipedia.org/wiki/ELIZA)</li>
<li class="fragment">1980s Multilayer FFNN</li>
<li class="fragment">1990 robotics and games</li>
<li class="fragment">2000 sports (basketball)</li>
<li class="fragment">2010 Deep learning</li>
<li class="fragment">2012 convolutional</li>
<li class="fragment">2013 hyperopt</li>
</ul>
</section>
<section class="slide level1">

<h2 id="turings-universal-computer">Turing's Universal Computer</h2>
<figure>
<img src="/talks/images/BYOB-article-2299245-18EE47A1000005DC-130_634x381.jpg" alt="After winning WWII by cracking the Enigma code, Turing designed the first Programmable Computer" /><figcaption>After winning WWII by cracking the Enigma code, Turing designed the first Programmable Computer</figcaption>
</figure>
<ul>
<li>Logic Gates (Relays)</li>
<li>Memory (Tape)</li>
</ul>
</section>
<section id="biological-brains" class="slide level1">
<h1>Biological Brains</h1>
<p>Neuroscientists simulated a <a href="http://openbrain.org">whole brain</a></p>
<div class="fragment">
<p>... of a nematode worm (C Elegans)</p>
<p>~300 neurons</p>
<p>~200 in central nervous system</p>
</div>
</section>
<section class="slide level1">

<figure>
<img src="/talks/images/BYOB-CelegansGoldsteinLabUNC.jpg" alt="C ElegansMost photographed organism of all time?" /><figcaption>C Elegans<br>Most photographed organism of all time?</figcaption>
</figure>
</section>
<section class="slide level1">

<h2 id="pretend-brains">Pretend Brains</h2>
<p>Artificial brains aren't at all like human brains,</p>
<p>. . .</p>
<p>or even a worm brain</p>
<p>Neuron simulations are broad abstractions - pulses in time not modeled - chemistry - neuron internal feedback loops</p>
<div>
<aside class="notes">
  
The &quot;artificial&quot; in AI is being replaced by &quot;Machine&quot;<br> Or you can think of artifical as &quot;pretend&quot;.<br> Or a model.<br> Like the model you have in your head for how the economy or the world works.<br> If you are nice people will be nice to you.<br> If you work hard, you'll get paid by your boss.<br>
</aside>
</div>
</section>
<section class="slide level1">

<h2 id="brain-really">Brain? Really?</h2>
<p>No, not <em>really</em>. Just pretend. In a computer.</p>
<div>
<aside class="notes">
  
Zeke pointed out that we're not building a brain, but an approximate model of a brain, an abstraciton<br> What you build today won't be able to have a conversation with you, but it might be able to tell you whether to bring your umbrella to work on Monday.<br> And it won't act in the physical world (except the light emitted from your laptop LEDs)<br>
</aside>
</div>
</section>
<section class="slide level1">

<h2 id="abstraction">Abstraction</h2>
<ul>
<li>18th century: stars modeled as crystal spheres</li>
<li>Copernicus: Earth at the center</li>
</ul>
<div>
<aside class="notes">
  
Too much complexity can hide the truth.<br> In the middle ages they could predict the motions of the stars to a few degrees<br> Now we can predict satellites, planets, stars to microradians (millimeters for satellites)
</aside>
</div>
</section>
<section class="slide level1">

<figure>
<img src="/talks/images/BYOB-C_elegans_male.svg" alt="C Elegans&#39; brain is shaped like a donut or our pharynx" /><figcaption>C Elegans' brain is shaped like a donut or our pharynx</figcaption>
</figure>
<div>
<aside class="notes">
  
What you build today won't be able to have a conversation with you, but it might be able to tell you whether to bring your umbrella to work on Monday.<br> And it won't act in the physical world (except the light emitted from)<br> It can't even slither through the dirt like this nematode worm<br>
</aside>
</div>
</section>
<section class="slide level1">

<h2 id="neuron">Neuron</h2>
<figure>
<img src="/talks/images/BYOB-biology-gray.png" alt="Typical animal neuron" /><figcaption>Typical animal neuron</figcaption>
</figure>
</section>
<section class="slide level1">

<h2 id="pretend-neuron">&quot;Pretend&quot; Neuron</h2>
<figure>
<img src="/talks/images/BYOB-biology-and-math.png" alt="Math mirrors life" /><figcaption>Math mirrors life</figcaption>
</figure>
</section>
<section class="slide level1">

<h2 id="math">Math</h2>
<ul>
<li>You don't need to know Linear Algebra, just...
<ul>
<li>multiply</li>
<li>add</li>
<li>check thresholds</li>
</ul></li>
<li>Equation/code is short (in python)</li>
<li>100s of neurons
<ul>
<li>Not billions</li>
</ul></li>
<li>Train for minutes
<ul>
<li>Not decades</li>
</ul></li>
</ul>
</section>
<section id="logic" class="slide level1">
<h1>Logic</h1>
</section>
<section class="slide level1">

<h2 id="mcculloch-pitts-neuron-mcp">McCulloch Pitts Neuron (MCP)</h2>
<p>Modeled after biological neurons. Can be combined to perform any logical or mathematical operation.</p>
<p>Binary output: 0 or +1 Any Number of <strong>binary</strong> inputs Inhibitory input with &quot;veto&quot; power</p>
</section>
<section class="slide level1">

<h2 id="lets-simulate">Let's Simulate</h2>
<ul>
<li>raise your hand if:
<ul>
<li>either of your neighbors raises her hand</li>
</ul></li>
<li>put your hand down:
<ul>
<li>either if both of your neighbors are same &quot;state&quot;</li>
</ul></li>
</ul>
</section>
<section class="slide level1">

<h2 id="xor">XOR</h2>
<figure>
<img src="/talks/images/BYOB-WolframRule82.png" alt="Cellular Automata, Wolfram Rule 82 = XOR" /><figcaption>Cellular Automata, Wolfram Rule 82 = XOR</figcaption>
</figure>
</section>
<section class="slide level1">

<h2 id="complexity">Complexity</h2>
<figure>
<img src="/talks/images/BYOB-File-CA_rule110_x3200_y3200_single.png" alt="Cellular Automata, Wolfram Rule 110 = Complex" /><figcaption>Cellular Automata, Wolfram Rule 110 = Complex</figcaption>
</figure>
</section>
<section class="slide level1">

<h2 id="game-of-life">Game of Life</h2>
<figure>
<img src="/talks/images/BYOB-File-Gospers_glider_gun.gif" alt="Game of Life gliders" /><figcaption>Game of Life gliders</figcaption>
</figure>
</section>
<section class="slide level1">

<h2 id="rosenblatts-perceptron">Rosenblatt's Perceptron</h2>
<p>Designed to be &quot;trainable&quot; Rosenblatt provided a training algorithm</p>
<p>Binary output: <strong>-1</strong> or +1 Any number of real inputs Threshold = 0 Weights and inputs can be real-valued</p>
</section>
<section class="slide level1">

<h2 id="lets-build-one">Let's Build One</h2>
<script src="https://gist.github.com/hobson/910f915910147d1ba9c0.js"></script>

</section>
<section class="slide level1">

<h2 id="ipython-notebook"><a href="https://github.com/totalgood/talks/blob/master/notebooks/BYOB-1948-Learn-to-be-Logical.ipynb">iPython Notebook</a></h2>
<figure>
<embed src="https://totalgood.github.io/talks/notebooks/BYOB-1948-Learn-to-be-Logical.ipynb" /><figcaption>Learned Logic</figcaption>
</figure>
</section>
<section class="slide level1">

<h2 id="modern-neurons">Modern Neurons</h2>
</section>
<section class="slide level1">

<h2 id="activation-functions">Activation functions</h2>
<ul>
<li>sigmoid</li>
<li>saturation</li>
<li>threshold</li>
<li>linear</li>
<li>sync</li>
<li>tanh</li>
</ul>
</section>
<section class="slide level1">

<h2 id="priorities-matter">Priorities Matter</h2>
<ul>
<li>Neanderthals' big eyes likely drove them to extinction<a href="#/fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></li>
<li>Too much of a good thing
<ul>
<li>Less room for imagination</li>
<li>Less neurons for social interaction</li>
</ul></li>
</ul>
<figure>
<img src="/talks/images/BYOB-Kermanshah_Pal_Museum-Neanderthal.jpg" alt="Neanderthals&#39; large eyes may have hurt their chances" /><figcaption>Neanderthals' large eyes may have hurt their chances</figcaption>
</figure>
</section>
<section class="slide level1">

<h2 id="lesson-depth-wins">Lesson: Depth Wins</h2>
<p>A deeper brain may be better</p>
<p>than</p>
<p>High resolution sensing</p>
</section>
<section class="slide level1">

<h2 id="layers">Layers</h2>
<ul>
<li>Many layers (6+ for)</li>
<li>Many neurons/layer</li>
<li>Sophisticated Connection Architectures
<ul>
<li>fully-connected</li>
<li>convolutional</li>
<li>recursive</li>
<li>sparse</li>
<li>random</li>
<li>scale-free</li>
</ul></li>
</ul>
</section>
<section class="slide level1">

<h2 id="neural-nets-were-made-for-...hyperdimensionality">Neural Nets were &quot;made&quot; for ...<br>Hyperdimensionality</h2>
<ul>
<li>Images (object recognition)</li>
<li>Sound (speech recognition)</li>
<li>Time series (weather, finance, election prediction)</li>
</ul>
</section>
<section class="slide level1">

<h2 id="pattern-recognition">Pattern Recognition</h2>
<ul>
<li class="fragment">Prediction</li>
<li class="fragment">Segmentation (sound, image)</li>
<li class="fragment">Feature detection</li>
<li class="fragment">Fraud detection</li>
<li class="fragment">Intrusion detection</li>
<li class="fragment">Game cheating detection . . .</li>
</ul>
<p>But often they can produce useful features that seemingly don't make sense</p>
<p>. . .</p>
<p>except for images</p>
</section>
<section class="slide level1">

<h2 id="neural-nets-help-when-...">Neural Nets help when ...</h2>
</section>
<section class="slide level1">

<h2 id="you-dont-know-what-to-look-forfeature-engineering">You don't know what to look for<br>(feature engineering)</h2>
<ul>
<li>FFT</li>
<li>DCT</li>
<li>Wavelets</li>
<li>PCA/SVD</li>
<li>RF</li>
<li>Statistics (mean, std, diff, polynomial)</li>
<li>LPF/BPF/HPF</li>
<li>Resampling/Interpolation/Extrapolation</li>
</ul>
</section>
<section class="slide level1">

<h2 id="and-when-...">And when ...</h2>
</section>
<section class="slide level1">

<h2 id="conventional-control-laws-fail">Conventional control laws fail</h2>
<ul>
<li>shooting a basketball</li>
<li>kicking a soccer ball</li>
<li>stabilizing an inverted pendulum</li>
<li>helicopter stunts</li>
</ul>
</section>
<section class="slide level1">

<h2 id="neural-nets-can-help-invert-physics-models">Neural Nets can help invert &quot;Physics&quot; models</h2>
<ul>
<li>Infer reflectance despite shadow/glare/haze</li>
<li>2-D image -&gt; 3-D object</li>
<li>When direct measurement of 3-D not possible
<ul>
<li>stereoscopic vision</li>
<li>structured light</li>
<li>lidar</li>
<li>radar</li>
<li>sonar</li>
<li>Kinect or RealSense</li>
</ul></li>
</ul>
</section>
<section class="slide level1">

<h2 id="nns-see-through-structured-noise">NNs &quot;see&quot; through structured noise</h2>
<p>Both images and sound often suffer from</p>
<ul>
<li>occlusion</li>
<li>obsucration/haze/fog/fade</li>
<li>rotation/translation/warping</li>
</ul>
</section>
<section class="slide level1">

<h2 id="nns-need-data-and-power">NNs need data and power</h2>
<ul>
<li>Lots of examples to learn from</li>
<li>CPU/GPU cycles to burn
<ul>
<li>Google speech recognition doesn't run on your phone...yet</li>
</ul></li>
</ul>
</section>
<section id="layers-1" class="slide level1">
<h1>Layers</h1>
</section>
<section class="slide level1">

<h2 id="classification">Classification</h2>
<ul>
<li>The most basic ML task is classification</li>
<li>Predict &quot;rain&quot; (1) &quot;no rain&quot; (0) for PDX tomorrow</li>
</ul>
</section>
<section class="slide level1">

<h2 id="supervised-learning">Supervised Learning</h2>
<p>We have historical &quot;examples&quot; of rain and shine</p>
<p><a href="http://wunderground.org">Weather Underground</a></p>
<p>Since we know the classification (training set)...</p>
<p>Supervised classification (association)</p>
</section>
<section class="slide level1">

<h2 id="rain-shine-partly-cloudy">Rain, Shine, Partly-Cloudy ?</h2>
<p>Wunderground lists several possible &quot;conditions&quot; or classes</p>
<p>If we wanted to predict them all</p>
<p>We would just make a binary classifier for each one</p>
<p>All classification problems can be reduced a binary classification</p>
</section>
<section class="slide level1">

<h2 id="perceptron"><a href="https://en.wikipedia.org/wiki/Perceptron"><em>Perceptron</em></a></h2>
<p>Sounds mysterious, like a &quot;flux capacitor&quot; or something...</p>
<p>It's just a multiply and threshold check:</p>
<p>{% highlight python %} if (weights * inputs) &gt; 0: output = 1 else: output = 0 {% endhighlight %}</p>
</section>
<section class="slide level1">

<h2 id="perceptron-1">Perceptron</h2>
</section>
<section class="slide level1">

<section class="right-align-all lightest-body-text" data-background="images/neural-nets-demystified.png">
  <h2 id="perceptron">
Perceptron
</h2>
<br><br><br><br><br><br><br><br><br><br><br><br>
</section>

</section>
<section class="slide level1">

<section class="right-align-all lightest-body-text" data-background="images/regression.png">
  <h2 id="regression">
Linear
</h2>
<br><br><br><br><br><br><br><br><br><br><br><br>
</section>

</section>
<section class="slide level1">

<section class="right-align-all lightest-body-text" data-background="images/time-series.png">
  <h2 id="regression">
Time Series
</h2>
<br><br><br><br><br><br><br><br><br><br><br><br>
</section>

</section>
<section class="slide level1">

<h2 id="need-something-a-little-better">Need something a little better</h2>
<p>Works fine for &quot;using&quot; (<em><a href="https://en.wikipedia.org/wiki/Activation_function">activating</a></em>) your NN</p>
<p>But for learning (<em><a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a></em>) you need it to be predictable...</p>
<ul>
<li>doesn't change direction on you: <em><a href="https://en.wikipedia.org/wiki/Monotonic_function">monotonic</a></em></li>
<li>doesn't jump around: <em><a href="https://en.wikipedia.org/wiki/Smoothness">smooth</a></em></li>
</ul>
</section>
<section class="slide level1">

<h2 id="sigmoid"><a href="https://en.wikipedia.org/wiki/Perceptron"><em>Sigmoid</em></a></h2>
<p>Again, sounds mysterious... like a transcendental function</p>
<p>It is a transcendental function, but the word just means</p>
<p>Curved, smooth like the letter &quot;C&quot;</p>
</section>
<section class="slide level1">

<h2 id="what-greek-letter-do-you-think-of-when-i-say-sigma">What Greek letter do you think of when I say &quot;Sigma&quot;?</h2>
<h2 id="σ">&quot;Σ&quot;</h2>
<p>What Roman (English) character?</p>
<ul>
<li>&quot;E&quot;?</li>
<li>&quot;S&quot;?</li>
<li>&quot;C&quot;?</li>
</ul>
</section>
<section class="slide level1">

<h2 id="sigma"><a href="https://en.wikipedia.org/wiki/Sigma">Sigma</a></h2>
<p>You didn't know this was a Latin/Greek class, did you...</p>
<p>Σ (uppercase) σ (lowercase) ς (last letter in word) c (alternatively)</p>
</section>
<section class="slide level1">

<p>Most English speakers think of an &quot;S&quot;</p>
<p>when they hear &quot;Sigma&quot;.</p>
<p>So the meaning has evolved to mean S-shaped.</p>
</section>
<section class="slide level1">

<h2 id="shaped-like-an-s">Shaped like an &quot;S&quot;</h2>
<p>The trainer (<em>(backpropagator)[https://en.wikipedia.org/wiki/Backpropagation]</em>) can predict the change in <code>weights</code> required Wants to nudge the <code>output</code> closer to the <code>target</code></p>
<p><code>target</code>: known classification for training examples <code>output</code>: predicted classification your network spits out</p>
</section>
<section class="slide level1">

<h2 id="but-just-a-nudge.">But just a nudge.</h2>
<p>Don't get greedy and push all the way to the answer Because your linear sloper predictions are wrong And there may be nonlinear interactions between the weights (multiply layers)</p>
<p>So set the learning rate () to somthething less than 1 the portion of the predicted nudge you want to &quot;dial back&quot; to</p>
</section>
<section id="code" class="slide level1">
<h1>Code</h1>
</section>
<section class="slide level1">

<h2 id="example-predict-rain-in-portland">Example: Predict Rain in Portland</h2>
<ul>
<li><a href="//github.com/pybrain2/pybrain2">PyBrain2</a></li>
<li><code>pip install pybrain2</code></li>
<li><a href="//github.com/totalgood/pug-ann">pug-ann</a></li>
<li><code>pip install pug-ann</code></li>
</ul>
</section>
<section class="slide level1">

<h2 id="visualizing-a-brain">Visualizing a Brain<a href="#/fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></h2>
<ul>
<li>watch the weights evolve</li>
<li>activate with examples and watch intermediate layers</li>
</ul>
</section>
<section class="slide level1">

<figure>
<img src="BYOB-W_output_column.png" alt="Output column heatmap" /><figcaption>Output column heatmap</figcaption>
</figure>
</section>
<section class="slide level1">

<figure>
<img src="BYOB-W_output_column.png" alt="Input row heatmap" /><figcaption>Input row heatmap</figcaption>
</figure>
</section>
<section class="slide level1">

<h2 id="get-historical-weather-for-portland-then-...">Get historical weather for Portland then ...</h2>
<ol type="1">
<li>Backpropagate: train a perceptron</li>
<li>Activate: predict the weather for tomorrow!</li>
</ol>
</section>
<section class="slide level1">

<h2 id="nn-advantages">NN Advantages</h2>
<ul>
<li>Easy
<ul>
<li>No math!</li>
<li>No tuning!</li>
<li>Just plug and chug.</li>
</ul></li>
<li>General
<ul>
<li>One model can apply to many problems</li>
</ul></li>
<li>Advanced
<ul>
<li>They often beat all other &quot;tuned&quot; approaches</li>
</ul></li>
</ul>
</section>
<section class="slide level1">

<h2 id="disadvantage-1-slow-to-learn">Disadvantage #1: Slow to Learn</h2>
<ul>
<li>cubic to learn
<ul>
<li>quadratic to activate</li>
</ul></li>
</ul>
</section>
<section class="slide level1">

<h2 id="example">Example</h2>
<ul>
<li>24+ hr for complex Kaggle example on laptop</li>
<li>90x30x20x10 ~= 1M DOF
<ul>
<li>90 input dimensions (regressors)</li>
<li>30 nodes for <em>hidden layer</em> 1</li>
<li>20 nodes for <em>hidden layer</em> 2</li>
<li>10 output dimensions (predicted values)</li>
</ul></li>
</ul>
</section>
<section class="slide level1">

<h2 id="disadvantage-2-they-dont-often-scale-difficult-to-parallelize">Disadvantage #2: They don't often scale (difficult to parallelize)</h2>
<ul>
<li>Fully-connected NNs can't be <em>easily</em> hyper-parallelized (GPU)
<ul>
<li>Large matrix multiplications</li>
<li>Layers depend on all elements of previous layers</li>
</ul></li>
</ul>
</section>
<section class="slide level1">

<h2 id="scaling-workaround">Scaling Workaround</h2>
<p>At Kaggle workshop we discussed paralleling linear algebra</p>
<ul>
<li>Split matrices up and work on &quot;tiles&quot;</li>
<li>Theano, <a href="">Keras</a> for python</li>
<li><a href="http://icl.cs.utk.edu/news_pub/submissions/plasma-scidac09.pdf">PLASMA</a> for BLAS</li>
</ul>
</section>
<section class="slide level1">

<h2 id="scaling-workaround-limitations">Scaling Workaround Limitations</h2>
<p>But tiles must be shared/consolidated and theirs redundancy</p>
<ul>
<li>Data flow: Main -&gt; CPU -&gt; GPU -&gt; GPU cache (and back)</li>
<li>Data com (RAM xfer) is limiting</li>
<li>Data RAM size (at each stage) is limiting</li>
<li><a href="http://icl.cs.utk.edu/news_pub/submissions/plasma-scidac09.pdf">Each GPU is equivalent to 16 core node</a></li>
</ul>
</section>
<section class="slide level1">

<h2 id="disadvantage-3-they-overfit">Disadvantage #3: They overfit</h2>
<ul>
<li>Too manu nodes = overfitting</li>
</ul>
</section>
<section class="slide level1">

<h2 id="what-is-the-big-o">What is the big O?</h2>
<ul>
<li>Degrees of freedom grow with number of nodes &amp; layers</li>
<li>Each layer's nodes connected to each previous layer's</li>
<li>That a lot of wasted &quot;freedom&quot;</li>
<li>Many weights are randomly zeroed/ignored (Random Dropout)</li>
</ul>
<h2 id="on2-to-activate">O(N^2) to activate</h2>
<h2 id="on3-to-learn">O(N^3) to learn</h2>
</section>
<section class="slide level1">

<h2 id="not-so-fast-big-o...">Not so fast, big O...</h2>
<p>{% highlight python %} &gt;&gt;&gt; np.prod([30, 20, 10]) 6000 &gt;&gt;&gt; np.sum([30, 20, 10])**2 3600 {% endhighlight %}</p>
</section>
<section class="slide level1">

<h2 id="rule-of-thumb">Rule of thumb</h2>
<p>NOT <code>N**2</code></p>
<p>But <code>M * N**2</code></p>
<p>N: number of nodes M: number of layers</p>
</section>
<section class="slide level1">

<h2 id="automated-architecture-limits">Automated Architecture Limits</h2>
<p><code>assert(M * N**2 &lt; len(training_set) / 10.)</code></p>
<p>I'm serious... put this into your code. I wasted a lot of time training models for Kaggle that was overfit.</p>
</section>
<section class="slide level1">

<h2 id="augment-with-your-brain">Augment with your Brain</h2>
<ul>
<li>Imprint your net with the structure of the problem
<ul>
<li>Feature engineering</li>
<li>Choose activation function</li>
<li>Partition your NN</li>
</ul></li>
<li>Prune and evolve your NN
<ul>
<li>Genetic algorithms</li>
</ul></li>
</ul>
</section>
<section class="slide level1">

<h2 id="this-is-a-virtuous-cycle">This is a virtuous cycle!</h2>
<ul>
<li>More structure (no longer fully connected)
<ul>
<li>Each independent path (segment) is parallelizable!</li>
</ul></li>
<li>Automatic tuning, pruning, evolving is all parallelizable!
<ul>
<li>Just train each NN separately</li>
<li>Check back in with Prefrontal to &quot;compete&quot;</li>
</ul></li>
</ul>
</section>
<section class="slide level1">

<h2 id="engineering">Engineering</h2>
<ul>
<li>limit connections</li>
</ul>
<p>jargon: <em>receptive fields</em></p>
<ul>
<li>limit weights</li>
</ul>
<p>jargon: <em>weight sharing</em></p>
<p>All the rage: <em>convolutional networks</em></p>
</section>
<section class="slide level1">

<h2 id="ideas">Ideas</h2>
<ul>
<li>limit weight ranges (e.g. -1 to 1, 0 to 1, etc)</li>
<li>weight &quot;snap to grid&quot; (snap learning)</li>
<li>dream up your own activation function</li>
<li>improve the back-propagation function</li>
</ul>
</section>
<section class="slide level1">

<p>Resources</p>
<ul>
<li><a href="http://keras.io/">keras.io</a>: Scalable Python NNs</li>
<li><a href="http://hagan.okstate.edu/NNDesign.pdf">Neural Network Design</a>: Free NN Textbook!</li>
<li><a href="https://github.com/hobson/pug-ann">pug-ann</a>: Helpers for PyBrain and Wunderground</li>
<li><a href="https://github.com/pybrain2/pybrain2">PyBrain2</a>: We're working on it</li>
</ul>
</section>
<section class="slide level1">

<p>Code highlighting test</p>
<p>{% highlight javascript %} function linkify( selector ) { if( supports3DTransforms ) {</p>
<pre><code>var nodes = document.querySelectorAll( selector );

for( var i = 0, len = nodes.length; i &amp;lt; len; i++ ) {
  var node = nodes[i];

  if( !node.className ) {
    node.className += &#39; roll&#39;;
  }
}</code></pre>
<p>} } {% endhighlight %}</p>
</section>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>http://cs231n.github.io/understanding-cnn/<a href="#/fnref1">↩</a></p></li>
<li id="fn2"><p>http://cs231n.github.io/understanding-cnn/<a href="#/fnref2">↩</a></p></li>
</ol>
</section>
    </div>
  </div>


  <script src="lib/js/head.min.js"></script>
  <script src="js/reveal.js"></script>

  <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,         // Display controls in the bottom right corner
        progress: true,         // Display a presentation progress bar
        history: true,          // Push each slide change to the browser history
        center: false,                       // Vertical centering of slides
        maxScale: 1.5,                  // Bounds for smallest/largest possible content scale
        slideNumber: false,                // Display the page number of the current slide
        theme: 'moon', // available themes are in /css/theme
        transition: 'fade', // default/cube/page/concave/zoom/linear/fade/none

        // Optional libraries used to extend on reveal.js
        dependencies: [
          { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
          { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
//          { src: 'plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; }, }
//          { src: 'plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
]});
    </script>
    </body>
</html>
